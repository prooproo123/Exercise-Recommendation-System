\documentclass[times, utf8,projekt]{fer}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{titlesec}

\begin{document}

% TODO: Navedite broj rada.
%\thesisnumber{000}

% TODO: Navedite naslov rada.
\title{Strojno učenje u adaptivnom učenju}

% TODO: Navedite vaše ime i prezime.
\author{Jelena Nemčić, Marin Ovčariček,Zvonimir Sučić,Ivana Žeger}

\maketitle
% stranice s napomenom o umetanju izvornika rada. Uklonite naredbu \izvornik ako želite izbaciti tu stranicu.
%\izvornik
% Dodavanje zahvale ili prazne stranice. Ako ne želite dodati zahvalu, naredbu ostavite radi prazne stranice.
%\zahvala{}
%\tableofcontents
%Dodati općenitu ideju projekta
\chapter{Uvod}
Adaptivno učenje u e-learning softverima tipično funkcionira tako da mjeri razinu znanja korisnika kroz početni skup pitanja, virtualnu simulaciju i/ili dodijeljene zadatke. Na temelju podataka prikupljenih iz odgovora korisnika, takav softver u stvarnom vremenu procjenjuje razliku između korisničkog znanja i znanja potrebnih za određenu kompetenciju, te odabire lekcije i zadatke za korisnika tako da minimizira količinu edukacijskog sadržaja koji tom korisniku prikazuje.

Konstrukcija algoritma za određivanje puta za adaptivno učenje tipično se radi na dva načina: 1) kreiranjem formalnog modela znanja za određenu domenu, a koji kreiraju eksperti iz te domene ili 2) koristeći algoritamski pristup baziran na teorijama Bayesian Knowledge Tracing i Item Response Theory koji na temelju odgovora polaznika edukacije procjenjuje vjerojatnost da je polaznik usvojio određenu vještinu/koncept (što ponovno zahtijeva unaprijed definirane vještine/koncepte).

U posljednje vrijeme, a s obzirom na dostupnost sve većih količina podataka (big data) ponovno su oživjele i dodatno se razvijaju tehnologije kreiranja grafova znanja (npr. pomoću dubokog učenja), a koji s obzirom na to da su kreirani statistički mogu biti mnogo kompleksniji i uže segmentirani (precizniji) u odnosu na one koje kreiraju eksperti nekog područja. Dodatno, prikupljanje velike količine informacija u različitim domenama omogućuje da kreiranje grafova znanja ne bude ograničeno samo na one tvrtke koje imaju golem broj korisnika kao što su Google ili Facebook). Na temelju inicijalnog istraživanja vjerujemo da se ova metoda može primijeniti i na kreiranje grafova znanja za adaptivno učenje, te time omogućiti s jedne strane znatno veću adaptivnost, a s druge strane veću jednostavnost kreiranja takvih grafova.

Ovo je posebno važno za područja edukacije izvan formalnog obrazovanja, gdje nisu strogo definirane ishodi učenja i testovi kojima se mjeri je li neki ishod učenja dostignut kod pojedinog polaznika. Dva primjera za to su instrukcije, gdje učeniku često nedostaju i predznanja iz drugih područja koje je ranije u školi trebao usvojiti, te korporativne edukacije, koje često obuhvaćaju ljude različitih struka i različitim znanjima iz domene za koju nastoje dobiti certifikat


\chapter{Cilj i postupak}
Stoga je cilj ovog projekta provjeriti sljedeće:
\begin{itemize}
\item Provjera mogućnosti kreiranja grafa znanja isključivo na temelju točnosti odgovora na zadacima iz jedne domene znanja koje korisnici daju i informacije o redoslijedu zadavanja zadataka pojedinom korisniku
\item Ako je navedeno moguće, potrebno je provjeriti može li se kreirati graf znanja na temelju rješavanja zadataka za istu domenu na temelju parcijalnog broja zadataka (što realnije reprezentira dostupne zadatke za stvarne domene – rijetko su dostupna baš sva znanja iz neke domene da bi se mogla kreirati zadaci koji pokrivaju baš svaku informaciju u toj domeni)
\item Ako je navedeno moguće, potrebno je provjeriti može li se isto napraviti i za neku domenu realnog znanja\newline
\end{itemize}

Ukratko, ovim se projektom provjerava može li se graf znanja potreban za adaptivno učenje kreirati metodama dubokog učenja na temelju ponašanja korisnika na zadacima (probabilistički), a bez potrebe za time da eksperti unaprijed određuju koncepte/vještine u koje se grupiraju zadaci ili čak sam graf znanja.\newline\newline
Za potrebe ove provjere kreirat će se:
\begin{itemize}
	\item umjetni, zatvoreni graf znanja 
	\item zadaci koji pokrivaju sve informacije prisutne u tom zatvorenom grafu znanja\newline
\end{itemize}
Potom će se zadaci dati testerima na rješavanje, tako da se:
\begin{itemize}
	\item varira redoslijed zadataka koje pojedini tester dobiva kako bi pokrio sve kombinacije
	\item bilježi točnost odgovora testera na zadatak
	\item u slučaju netočnog odgovora testeru se prikazuje točna informacija.
\end{itemize}

\chapter{Bayesian knowledge tracing (BKT)}
\section{Općenito o BKT}
Bayesian Knowledge Tracing koristi Hidden Markov Model i ima 4 osnovna parametra:
\begin{itemize}
	\item p(L0) - vjerojatnost da je korisnik a priori savladao gradivo
	\item p(G) - vjerojatnost da je korisnik pogodio točan odgovor bez da ima potrebno znanje	
	\item p(S) - vjerojatnost da je korisnik krivo odgovorio iako ima potrebno znanje	
	\item p(T) - vjerojatnost da je znanje prešlo iz NE ZNA u ZNA nakon prilike da se primjeni znanje
\end{itemize}
Kao izlaz dobivaju se vrijednosti:
\begin{itemize}
	\item p(L) - vjerojatnost ovladavanja vještinom (eng. probability of skill mastery)
	\item p(C) - vjerojatnost da će korisnik ispravno primijeniti vještinu u budućnosti (eng. probability of the student correctly applying the skill on a future practice)\newline
\end{itemize}

\begin{equation}
 p(L_t\mid obs=correct)=\frac{p(L_t)*(1-p(S))}{p(L_t)*(1-p(S)+(1-p(L_t)*p(G))}
\end{equation}\newline
\begin{equation}
 p(L_t\mid obs=wrong)=\frac{p(L_t)*p(S)}{p(L_t)*p(S)+(1-p(L_t)*(1-p(G))}
\end{equation}\newline
\begin{equation}
 p(L_{t+1})=p(L_t\mid obs=correct) + (1-p(L_t\mid obs=correct))*p(T)
\end{equation}\newline
\begin{equation}
 p(C_{t+1})=p(L_{t+1}) * (1-p(S)) + p(L_{t+1})*p(G)
\end{equation}

\section{Ideje}
Prvobitna ideja je bila da se p(L0) računa iz inicijalnih pitanja, vrijednosti p(G) i p(S) bi se prema preporuci iz rada(trebalo bi pronaći kojeg i baciti referencu) stavile na interval [0,0.3], [0,0.1] te bi se p(T) postavio prema preporuci eksperta što ne želimo jer je cilj ovog projekta da smanjimo zadatke eksperata na minimum.

To je ukazalo na potrebu pronalaska algoritama koji bi uz pomoć nekog skupa podataka aproksimirali parametre za BKT.
\section{Problemi i zadaci}
\begin{itemize}
	\item proučiti parametar p(T)
	\item proučiti kodove sa githuba kako bi se dobila ideja kako algoritam funkcionira
	\item napraviti malu implementaciju s malo pitanja i provjeriti radi li
	\item proučiti parameter fitting uz pomoć EM algoritma, stohastic gradient descenta ili neke druge metode
	\item kako napraviti input dataset, prikupiti podatke
	
	
\end{itemize}
\section{Dobivanje BKT parametara}
\subsection{EM (expectation-maximization) algoritam}

\begin{itemize}
	\item iterativni algoritam za pronalaženje (aproksimiranje) najveće izglednosti (eng. maximum likelihood) ili maksimalne a posteriori (MAP) procjene parametara u statističkim modelima
	\item model ovisi o nepoznatim latentnim varijablama
	\item EM iteracija sadrži 2 koraka:
	\begin{itemize}
		\item 	korak očekivanja (E), koji stvara funkciju za očekivanje log-izglednosti koja se procjenjuje pomoću trenutne procjene parametara, procjenjuju se vrijednosti latentnih varijabli
		\item 	korak maksimizacije (M), koji izračunava parametre distribucije koji maksimiziraju očekivanu log-izglednost pronađenu u E koraku, ti se parametri zatim koriste za procjenu latentnih varijabli u sljedećem E koraku
	\end{itemize}
	
	\item primjenjuje se kada želimo odrediti parametre distribucije (normalna, eksponencijalna, …)
	\item problem: za korištenje potrebo znati distribuciju podataka ili točne vrijednosti (eng. true values) traženih parametara
	
\end{itemize}
Kroz ovo istraživanje nije pronađena niti jedna implementacija EM algoritma za aproksimaciju BKT parametara niti je napravljena vlastiti implementacija zbog prevelikog praga znanja matematike.

\subsection{Grid search i Simulated Annealing}
Pronađen je kod napisan u Javi koji računa BKT parametre tehnikom simuliranog kaljenja \url{https://github.com/wlmiller/BKTSimulatedAnnealing}. U README na githubu se također spominjao kod koji je bio baza za to, on je koristio običan grid search kako bi izračunao parametre. Oba koda su prevedena u python i prilagođena našim skupovima podataka. Na kraju se ispostavilo da je "simulirano kaljenje" povoljnije te se grid search odbacio.
\section{Rezultati}
\begin{itemize}
	\item napravljen google forms kviz sa 20 pitanja iz biologije, ispitanici moraju odgovoriti na svih 20 pitanja kako bi podaci ušli u dataset
	\item napravljena python skripta koja pretvara podatke dobivene iz google formsa u oblik prikladan za treniranje BKT-a i pronalaženje parametara
	\item pronađen je kod u Javi koji tehnikom simuliranog kaljenja aproksimira parametre za BKT uz pomoć danog dataseta, kod je preveden u python skript
	\item napravljena python skripta za BKT koja određuje vjerojatnost da je ispitanik naučio/  savladao gradivo
	\item uz pomoć skripte za aproksimaciju BKT parametara, nađene su njihove vrijednosti za svaku vještinu iz ASSISTMENTS dataseta i pohranjenje u google sheets tablicu
	\item dobiveni parametri algoritmom simuliranog kaljenja uspoređeni su s onima dobivenima pomoću grid search metode -> vrijednosti parametara su skoro iste, vrlo male razlike
	\item napravljen google forms kviz sa po 6 pitanja iz 5 koncepata, izračunati su parametri za taj dataset
	\item BKT kod i kod za aproksimaciju BKT parametara su se dalje koristili u bilježnicama za izgradnju grafa probabilističkim metodama
	
\end{itemize}
\section{Poveznice}
\subsection{BKT}
\url{https://en.wikipedia.org/wiki/Bayesian_Knowledge_Tracing}\newline
\url{http://www.cs.cmu.edu/~./ggordon/yudelson-koedinger-gordon-individualized-bayesian-knowledge-tracing.pdf}\newline
\url{https://github.com/CAHLR/pyBKT/blob/master/README.md}\newline
\url{https://www.learnlab.org/uploads/mypslc/publications/bca2008v.pdf}\newline
\url{https://www.upenn.edu/learninganalytics/ryanbaker/paper_143.pdf}\newline
\url{https://github.com/yemao616/Bayesian-Knowledge-Tracing}\newline
\url{http://www.cs.cmu.edu/~./ggordon/yudelson-koedinger-gordon-individualized-bayesian-knowledge-tracing.pdf}\newline
\url{https://www.fi.muni.cz/~xpelanek/publications/umuai-overview.pdf}\newline
\url{https://medium.com/@joyboseroy/modelling-a-students-learning-34375b0131dd}\newline
\url{https://www.math.vu.nl/~sbhulai/publications/data_analytics2018c.pdf}\newline
\subsection{Pronalaženje parametara}
\url{https://www.fmrib.ox.ac.uk/datasets/techrep/tr00yz1/tr00yz1/node9.html}\newline
\url{https://github.com/wlmiller/BKTSimulatedAnnealing/blob/master/computeKTparams_SA.java}\newline
\url{https://www.upenn.edu/learninganalytics/ryanbaker/paper_143.pdf}\newline
\url{https://educationaldatamining.org/files/conferences/EDM2018/papers/EDM2018_paper_14.pdf}\newline
\url{http://yudelson.info/hmm-scalable/}\newline
\url{https://www.educationaldatamining.org/EDM2015/proceedings/short364-367.pdf}\newline
\url{https://concord.org/wp-content/uploads/2016/12/pdf/tracking-student-progress-in-a-game-like-learning-environment.pdf}\newline
\url{https://tinyheero.github.io/2016/01/03/gmm-em.html}\newline
\url{https://machinelearningmastery.com/expectation-maximization-em-algorithm/}\newline
\url{http://rstudio-pubs-static.s3.amazonaws.com/1001_3177e85f5e4840be840c84452780db52.html}\newline
\url{https://www.colorado.edu/amath/sites/default/files/attached-files/em_algorithm.pdf}
\chapter{Bayes graf}
	\section{Uvod}
	
	Ideja je napraviti vlastiti model koji iz skupa podataka računa vjerojatnost savladavanja koncepata te se prema njima gradi graf znanja.
	
	Prvi pristup je račun uvjetnih vjerojatnosti $p(Y_j\mid X_i)$
	
	Najveći problem u oba pristupa je to što pokušavamo dobiti ovisnosti među konceptima,a ne pitanjima. Za razliku od pitanja za koncepte se ne može reći da ih se zna/ne zna jer se oni sastoje od više pitanja te se može samo gledati postotak riješenosti za svakog studenta / prosječan postotak riješenosti. Prosječan postotak rješenosti se može gledati kao pripadnost neizrazitom skupu ZNA odnosno 1- postotak riješenosti kao pripadnost skupu NE ZNA, to komplicira stvari kod Bayesovog zaključka. Potrebno je pronaći/proučiti postoji li ekvivalent Bayesovog zaključka kada se koriste neizraziti skupovi odnosno kontinuirane vrijednosti [0,1].
\chapter{Zaključak}
Zaključak.

\bibliography{literatura}
\bibliographystyle{fer}

\begin{sazetak}
Sažetak na hrvatskom jeziku.

\kljucnerijeci{Ključne riječi, odvojene zarezima.}
\end{sazetak}

% TODO: Navedite naslov na engleskom jeziku.
\engtitle{Title}
\begin{abstract}
Abstract.

\keywords{Keywords.}
\end{abstract}

\end{document}

% TODO: Ne radi bibtex,jel mi treba?